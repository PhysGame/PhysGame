model:
  arch: llava_interleave
  llama_model: llava-hf/llava-onevision-qwen2-7b-si-hf
  video_input: 'mean'
  gradient_checkpointing: True
  pooling: clipST_3d
  clip_weight: google/siglip-so400m-patch14-384
  pooling_kernel: (2,3,3)
  pooling_stride: (2,3,3)
  image_pooling_kernel: (1,3,3)
  image_pooling_stride: (1,3,3)
  frame_shape: (27,27)
  freeze_vproj: False
  freeze_tproj: False
  freeze_text: False
  btadapter: False
  long_clip: True
  freeze_LLM: False
  pad_token_id: 0

datasets:
  interleave_datasets:
    # m4_multi_image: {}
    llava_1p5: {}
    llava_hound_300k:
      num_frames: 32
      video_reader_type: 'rawframe'
    glitches_video:
      num_frames: 32
    # reasoning_next_qa:
    #   num_frames: 32
    # caption_videochatgpt_full_flat:
    #   num_frames: 32
    #   video_reader_type: 'rawframe'
    # classification_k400:
    #   num_frames: 32
    # classification_ssv2:
    #   num_frames: 32
    # reasoning_clevrer_qa:
    #   num_frames: 32
    # reasoning_clevrer_mc:
    #   num_frames: 32
    # vcg_not_in_llava:
    #  num_frames: 32
    #  video_reader_type: 'rawframe'


run:
  task: interleave_sft
  bf16: True
  fp16: False
  tf32: False
  output_dir: "./physvlm/interleave_sft_output"
  num_train_epochs: 1
  dataloader_num_workers: 4
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  evaluation_strategy: "no"
  learning_rate: 1e-5
  weight_decay: 0.
  warmup_ratio: 0.03
  lr_scheduler_type: 'cosine'
  logging_steps: 50
  model_max_length: 1024
  save_strategy: "epoch" 
  save_total_limit: 1
  deepspeed: 'physvlm/train/zero3.json'
